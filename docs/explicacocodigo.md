# Explica√ß√£o do C√≥digo

Este documento resume como os principais componentes da aplica√ß√£o (API FastAPI e painel Streamlit) funcionam por dentro. Use-o como refer√™ncia r√°pida ao revisar o reposit√≥rio `industrial-dual-rag`.

## 1. API (`api/main.py`)

### 1.1 Estrutura geral
- [`Configura√ß√£o global`](../api/main.py#L1-L117) carrega vari√°veis de ambiente, inicializa caminhos (`DATA_DIR`, `UPLOAD_DIR`, `SUMMARY_OUTPUT_DIR`) e garante a cria√ß√£o das pastas dentro do volume `./data/api`.
- [`FastAPI` + modelos Pydantic](../api/main.py#L996-L1450) definem endpoints para upload/reindexa√ß√£o, `/chat`, logging e consolida√ß√£o de m√©tricas.
- [`Clientes vetoriais e cache de embeddings`](../api/main.py#L90-L170) mant√™m um `chromadb.PersistentClient` compartilhado e inst√¢ncias `HuggingFaceEmbeddings` reutiliz√°veis para evitar recarregamentos caros.

### 1.2 Ingest√£o de documentos
- [`upload_manual`](../api/main.py#L1004-L1071) recebe um PDF via `UploadFile`, grava no `UPLOAD_DIR`, valida par√¢metros e dispara as etapas abaixo:
  - [`extract_text_from_pdf`](../api/main.py#L212-L235) usa `pypdf` para juntar o texto das p√°ginas, com tratamento de erro detalhado.
  - [`chunk_text`](../api/main.py#L177-L195) divide o texto em janelas configur√°veis (`chunk_size`, `chunk_overlap`).
  - [`upsert_chunks_to_backend`](../api/main.py#L540-L620) distribui os chunks para o backend escolhido (`chroma`, `faiss`, `weaviate`, `pinecone`), preenchendo metadados (`source`, `chunk_size`, `embedding_model`, `backend`).
- [`reindex_manuals`](../api/main.py#L1072-L1161) reaproveita PDFs j√° armazenados para regenerar embeddings ao trocar backend ou par√¢metros de chunking, contabilizando arquivos processados e ignorados.

### 1.3 Consulta vetorial e debug
- [`query_backend`](../api/main.py#L622-L697) executa busca sem√¢ntica com `top_k=3` para todos os backends: usa `collection.query(..., n_results=top_k)` no Chroma e `similarity_search(..., k=top_k)` nas integra√ß√µes LangChain.
- [`build_vector_debug`](../api/main.py#L735-L784) reconstr√≥i embeddings da pergunta e dos chunks usando o mesmo `HuggingFaceEmbeddings`, calcula similaridade cosseno com [`cosine_similarity`](../api/main.py#L722-L733) e inclui previews/vetores completos no payload e no CSV quando logging est√° ativo.

### 1.4 Telemetria e montagem do prompt
- [`build_telemetry_section`](../api/main.py#L786-L828) normaliza o snapshot da UI, respeita `telemetry_signals`, gera alertas e devolve o dicion√°rio filtrado para logging.
- [`run_diagnosis`](../api/main.py#L1301-L1447) orquestra todo o fluxo:
  1. Decide o cen√°rio e, se necess√°rio, chama novamente [`query_backend`](../api/main.py#L622-L697) para obter contexto est√°tico.
  2. Monta blocos opcionais de instru√ß√µes (`instructions_block`) e formato JSON (`response_format_block`).
  3. Concatena `base_system`, contexto est√°tico, telemetria formatada e pergunta no `final_prompt`.
  4. Invoca [`get_llm_response`](../api/main.py#L850-L991), que encapsula Groq, Gemini e Ollama (sem mocks: qualquer erro real √© propagado).
  5. Chama [`estimate_tokens`](../api/main.py#L698-L711) para estimar o uso de tokens e devolve metadados (modo utilizado, backend, vetores, telemetria aplicada).

### 1.5 M√©tricas, logging e relat√≥rios
- A UI calcula m√©tricas via [`compute_text_metrics`](../web/app.py#L497-L533); a API apenas recebe os valores em [`log_experiment`](../api/main.py#L1245-L1286) e persiste no CSV `experiment_logs.csv`.
- [`ensure_experiment_log_schema`](../api/main.py#L488-L531) garante que o CSV tenha o cabe√ßalho atualizado sempre que novas colunas s√£o introduzidas.
- [`generate_experiment_summary`](../api/main.py#L236-L487) consolida o hist√≥rico, salva `summary_metrics.csv`, `recent_samples.csv` e gr√°ficos Plotly (HTML), al√©m de limpar artefatos antigos para evitar confus√µes.

## 2. Painel Streamlit (`web/app.py`)

### 2.1 Configura√ß√£o e estado
- [`env_or_default` + constantes iniciais](../web/app.py#L38-L167) carregam `.env`, definem modelos/backends padr√£o e finalizam com `st.set_page_config`.
- O bloco de [`st.session_state`](../web/app.py#L286-L377) persiste telemetria, hist√≥rico de diagn√≥sticos, caches de modelos e par√¢metros de chunking/embedding.
- M√©tricas sem√¢nticas s√£o tratadas por [`get_bert_scorer`](../web/app.py#L233-L283), [`get_active_bert_tokenizer`](../web/app.py#L181-L190) e [`truncate_for_bertscore`](../web/app.py#L192-L211), mantendo tokens alinhados ao c√°lculo de BERTScore.

### 2.2 MQTT e simulador
- [`start_mqtt`](../web/app.py#L349-L381) configura o cliente `paho.mqtt.client`, assina `MQTT_TOPIC_SENSORS` e injeta mensagens na [`Queue`](../web/app.py#L319-L333) criada por `get_mqtt_queue`.
- [`pump_mqtt_queue`](../web/app.py#L384-L402) atualiza `st.session_state.telemetry`, abastecendo os cards e o payload enviado aos endpoints.
- Bot√µes ‚ÄúOpera√ß√£o Normal/Falha T√©rmica/Desbalanceamento‚Äù chamam [`publish_command`](../web/app.py#L439-L454), que publica comandos MQTT para o simulador.

### 2.3 UI e intera√ß√£o com a API
- A [`sidebar`](../web/app.py#L584-L777) controla provedor/modelo LLM, par√¢metros de chunking, backend vetorial, sele√ß√£o de sinais e upload/reprocessamento (POST `/upload` e `/reindex`).
- A √°rea principal entre [`st.title` e o painel de controle`](../web/app.py#L778-L905) mostra telemetria, simulador de falhas e sele√ß√£o de cen√°rio (1‚Äì3) com configura√ß√£o de prompts.
- O bot√£o [‚ÄúGerar Relat√≥rio de Diagn√≥stico‚Äù](../web/app.py#L907-L1058) monta o payload completo e chama `POST /chat`. Quando ‚ÄúGravar logs de experimentos‚Äù est√° ativo:
  1. Solicita o gabarito ao usu√°rio.
  2. Executa [`compute_text_metrics`](../web/app.py#L497-L533) para accuracy/BLEU/ROUGE-L/BERTScore.
  3. Envia tudo via [`persist_experiment_log`](../web/app.py#L456-L495), incluindo `vector_debug` quando dispon√≠vel.
- O bot√£o [‚Äúüìä Gerar resumo autom√°tico‚Äù](../web/app.py#L738-L777) dispara `/experiments/summarize` e exibe os artefatos da pasta `data/api/summaries`.

### 2.4 Visualiza√ß√£o de resultados
- Ap√≥s uma resposta, o painel em [`st.session_state.diagnosis_history`](../web/app.py#L1061-L1235) destaca modo utilizado, backend vetorial, tokens e contexto.
- Com `debug` ativo, mostramos o prompt final, chunks e telemetria. O bloco usa [`render_vector_preview`](../web/app.py#L535-L567) para exibir `vector_debug`, incluindo expansor com o vetor completo.

## 3. Rela√ß√£o entre API e Web

1. **Ingest√£o**: a UI chama [`/upload`](../api/main.py#L1004-L1071) e [`/reindex`](../api/main.py#L1072-L1161) para manter os vetores sincronizados; todo o chunking/embedding vive na API.
2. **Diagn√≥stico**: o front monta o payload no [handler do bot√£o de diagn√≥stico](../web/app.py#L907-L1058), enquanto a API consolida tudo em [`run_diagnosis`](../api/main.py#L1301-L1447) antes de chamar o LLM escolhido.
3. **M√©tricas**: o Streamlit calcula m√©tricas via [`compute_text_metrics`](../web/app.py#L497-L533) e envia para [`/experiments/log`](../api/main.py#L1245-L1286); a API apenas persiste e consolida (via [`generate_experiment_summary`](../api/main.py#L236-L487)).
4. **Auditoria**: `vector_debug`, tokens e telemetria retornam de [`run_diagnosis`](../api/main.py#L1301-L1447) e s√£o apresentados pela UI (debug expander + [`render_vector_preview`](../web/app.py#L535-L567)) para explicar ‚Äúcomo‚Äù o diagn√≥stico foi produzido.

Com este panorama voc√™ consegue navegar pelo c√≥digo e entender onde cada parte da l√≥gica reside sem precisar reler todos os arquivos do zero.