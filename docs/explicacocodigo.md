# Explica√ß√£o do C√≥digo

Este documento resume como os principais componentes da aplica√ß√£o (API FastAPI e painel Streamlit) funcionam por dentro. Use-o como refer√™ncia r√°pida ao revisar o reposit√≥rio `industrial-dual-rag`.

## 1. API (`api/main.py`)

### 1.1 Estrutura geral
- Carrega vari√°veis de ambiente e define caminhos persistentes em `DATA_DIR`, mantendo uploads, √≠ndices e logs dentro do volume `./data/api`.
- Inicializa um `FastAPI` com endpoints para upload/reindexa√ß√£o de PDFs, execu√ß√£o de diagn√≥sticos (`/chat`), logging de experimentos e consolida√ß√£o de m√©tricas.
- Mant√©m um cliente `chromadb.PersistentClient` compartilhado e caches de embeddings `HuggingFaceEmbeddings` para evitar recarregamentos caros.

### 1.2 Ingest√£o de documentos
- `upload_manual` recebe um PDF via `UploadFile`, grava em `UPLOAD_DIR` e chama:
  - `extract_text_from_pdf` ‚Üí usa `pypdf` para juntar o texto das p√°ginas.
  - `chunk_text` ‚Üí divide em janelas configur√°veis (`chunk_size`, `chunk_overlap`).
  - `upsert_chunks_to_backend` ‚Üí envia os chunks para o backend vetorial escolhido (`chroma`, `faiss`, `weaviate`, `pinecone`). Cada metadado inclui `source`, `chunk_size`, `embedding_model` e `backend`.
- `reindex_manuals` reutiliza PDFs j√° salvos para regenerar embeddings quando o usu√°rio altera backend ou par√¢metros de chunking.

### 1.3 Consulta vetorial e debug
- `query_backend` aplica busca sem√¢ntica com `top_k=3` em todos os backends. No Chroma usamos `collection.query(..., n_results=top_k)`, nos demais LangChain faz `similarity_search(..., k=top_k)`.
- `build_vector_debug` reconstr√≥i os vetores da pergunta e dos chunks recuperados usando o mesmo `HuggingFaceEmbeddings`, computa similaridade cosseno (`cosine_similarity`) e envia previews + embeddings completos no payload de resposta e no CSV (quando logging est√° ativo).

### 1.4 Telemetria e montagem do prompt
- `build_telemetry_section` normaliza o snapshot enviado pela UI, aplica as chaves selecionadas e gera o bloco textual com alertas (‚ÄúTemperatura acima do limite cr√≠tico‚Äù). Tamb√©m retorna o dicion√°rio filtrado para logging.
- `run_diagnosis` √© o endpoint central:
  1. Determina cen√°rio (baseline, RAG docs, RAG + telemetria) e recupera chunks conforme necess√°rio.
  2. Monta se√ß√µes opcionais de instru√ß√µes e formato JSON (`response_format`).
  3. Concatena `base_system`, contexto est√°tico, telemetria e pergunta no `final_prompt`.
  4. Chama `get_llm_response`, que abstrai Groq, Gemini ou Ollama (cada um com seu SDK). N√£o h√° fallback simulado‚Äîse a chamada real falhar, retornamos o erro.
  5. Estima tokens com `estimate_tokens` (tiktoken se dispon√≠vel, caso contr√°rio contagem de palavras) e devolve metadados (modo usado, backend vetorial, vetores, tokens, sinais de telemetria aplicados).

### 1.5 M√©tricas, logging e relat√≥rios
- `compute_text_metrics` n√£o vive na API; a UI calcula accuracy/BLEU/ROUGE/BERTScore localmente. A API apenas recebe os valores via `/experiments/log` e persiste no CSV `experiment_logs.csv`.
- `ensure_experiment_log_schema` garante que o CSV tenha o cabe√ßalho esperado, reescrevendo linhas existentes quando evolu√≠mos as colunas.
- `generate_experiment_summary` l√™ o CSV, agrega m√©tricas (por cen√°rio e modo), exporta `summary_metrics.csv`, `recent_samples.csv` e gr√°ficos Plotly (HTML). Tamb√©m limpa artefatos antigos para evitar confus√£o.

## 2. Painel Streamlit (`web/app.py`)

### 2.1 Configura√ß√£o e estado
- Carrega `.env`, define constantes (modelos default, backends suportados, sinais de telemetria) e chama `st.set_page_config`.
- Usa `st.session_state` para persistir telemetria, hist√≥rico de diagn√≥sticos, caches de modelos LLM e par√¢metros de chunking/embedding.
- Implementa cache de m√©tricas sem√¢nticas com `_instantiate_bert_scorer` + `get_bert_scorer`. Agora o app carrega tamb√©m o tokenizer (`AutoTokenizer`) para truncar entradas longas via `truncate_for_bertscore`, mantendo a m√©trica BERTScore est√°vel.

### 2.2 MQTT e simulador
- `start_mqtt` configura o cliente `paho.mqtt.client`, assina o t√≥pico definido pelas vari√°veis `MQTT_BROKER`, `MQTT_TOPIC_SENSORS` e deposita mensagens numa `Queue` compartilhada (`get_mqtt_queue`).
- `pump_mqtt_queue` atualiza `st.session_state.telemetry`, alimentando os cards do painel e o payload enviado ao backend.
- Bot√µes ‚ÄúOpera√ß√£o Normal‚Äù, ‚ÄúFalha T√©rmica‚Äù, ‚ÄúDesbalanceamento‚Äù chamam `publish_command`, que publica comandos MQTT para o simulador.

### 2.3 UI e intera√ß√£o com a API
- Sidebar controla provedor/modelo LLM, par√¢metros de chunking, backend vetorial e sele√ß√£o de sinais. Uploads/reprocessamentos fazem POST para `/upload` e `/reindex`.
- A √°rea principal mostra telemetria (cards), controles do simulador, sele√ß√£o de cen√°rio (1, 2, 3) e editor do prompt (base system, instru√ß√µes, JSON de sa√≠da).
- O bot√£o ‚ÄúGerar Relat√≥rio de Diagn√≥stico‚Äù monta o payload e chama `POST /chat`. Quando o checkbox ‚ÄúGravar logs de experimentos‚Äù est√° ativo, a UI:
  1. Solicita o gabarito (refer√™ncia) do usu√°rio.
  2. Executa `compute_text_metrics`, calculando accuracy, BLEU, ROUGE-L e BERTScore (com truncamento/tokenizer alinhado ao core).
  3. Chama `persist_experiment_log`, enviando m√©tricas + vetores para a API.
- O bot√£o ‚Äúüìä Gerar resumo autom√°tico‚Äù dispara `/experiments/summarize` e exibe os artefatos gerados na pasta `data/api/summaries`.

### 2.4 Visualiza√ß√£o de resultados
- Ap√≥s uma chamada bem-sucedida, o app exibe o relat√≥rio retornado pela API, destacando o modo utilizado, backend vetorial, uso de tokens e se houve contexto.
- Se `debug` estiver marcado, mostramos:
  - Prompt final concatenado.
  - Chunks recuperados e seus metadados.
  - Telemetria de fato inserida no prompt.
  - `vector_debug` com pr√©-visualiza√ß√£o dos embeddings e similaridade (primeiras dimens√µes em tabela + expander com vetor completo).

## 3. Rela√ß√£o entre API e Web

1. **Ingest√£o**: UI chama `/upload`/`/reindex` para manter os vetores sincronizados. N√£o h√° l√≥gica de chunking no Streamlit‚Äîtudo reside na API.
2. **Diagn√≥stico**: UI monta o payload com a telemetria em tempo real, instru√ß√µes e formato de resposta; API combina com os chunks recuperados e chama o LLM selecionado.
3. **M√©tricas**: UI calcula metrics e envia para `/experiments/log`. O core offline (`core/industrial_dual_rag.py`) usa a mesma l√≥gica (inclusive truncamento de BERTScore) para garantir consist√™ncia.
4. **Auditoria**: `vector_debug`, tokens e telemetria s√£o retornados pela API e apresentados na UI/logs, permitindo explicar ‚Äúcomo‚Äù o diagn√≥stico foi produzido.

Com este panorama voc√™ consegue navegar pelo c√≥digo e entender onde cada parte da l√≥gica reside sem precisar reler todos os arquivos do zero.