# Industrial Dual-Context RAG: Cyber-Physical Diagnosis System

Este reposit√≥rio cont√©m a implementa√ß√£o de um sistema de Gera√ß√£o Aumentada por Recupera√ß√£o (RAG) aplicado ao contexto industrial. O projeto investiga o impacto da fus√£o de Contexto Est√°tico (Manuais T√©cnicos PDF) e Contexto Din√¢mico (Telemetria IoT via MQTT) na precis√£o de diagn√≥sticos gerados por Grandes Modelos de Linguagem (LLMs).

Projeto desenvolvido como requisito para a disciplina de IA Generativa (Mestrado em Engenharia de Automa√ß√£o e Sistemas).

## Arquitetura do Sistema

O sistema √© composto por tr√™s m√≥dulos principais orquestrados via Docker:

1. Simulador IoT (/simulator):

* Simula uma m√°quina industrial (ex: Torno CNC).
* Gera dados sint√©ticos de vibra√ß√£o, temperatura e corrente.
* Permite inje√ß√£o de falhas (Superaquecimento, Desbalanceamento) via comandos MQTT.

2. API RAG (/api):

* Backend FastAPI: Gerencia o pipeline de infer√™ncia.
* Vector Database configur√°vel (ChromaDB, FAISS, Weaviate e Pinecone): armazena embeddings dos manuais t√©cnicos (Contexto Est√°tico).
* LLM Gateway: Conecta-se a modelos externos (Groq, Gemini) ou locais.
* L√≥gica de Experimento: Monta o prompt dinamicamente baseada no cen√°rio escolhido (1, 2 ou 3), permitindo ajuste de `base_system`, instru√ß√µes e formato de resposta JSON.
* M√©tricas autom√°ticas (accuracy, BLEU, ROUGE-L, lat√™ncia e tokens) persistidas em CSV quando o registro de experimentos est√° ativo.

3. Interface do Operador (/web):

* Frontend Streamlit: Dashboard para visualiza√ß√£o de dados.
* Cliente MQTT: Assina t√≥picos de sensores para exibir dados em tempo real.
* Controle Experimental: Permite upload de PDFs, escolha do backend vetorial, par√¢metros de chunking/embedding, inje√ß√£o de falhas, edi√ß√£o do prompt base/instru√ß√µes/JSON e sele√ß√£o de cen√°rio RAG.
* Registro de Experimentos: coleta m√©tricas e gabaritos opcionais; notebook em `/notebooks/experiment_summary.ipynb` consolida os resultados em tabelas e gr√°ficos.

## Fluxo de Dados

1. Loop de Telemetria (Tempo Real)
```
[Simulador] --(JSON via MQTT)--> [Broker] --(Subscri√ß√£o)--> [Interface Web]
```
* O simulador publica dados a cada 2 segundos.
* A interface web atualiza o estado da sess√£o (Session State) com a √∫ltima leitura.

2. Loop de Diagn√≥stico (On-Demand)

````
[Usu√°rio] + [Estado Atual] --> [API] --> [ChromaDB] + [LLM] --> [Diagn√≥stico]
````

Quando o usu√°rio solicita um diagn√≥stico, o fluxo depende do cen√°rio:

* Cen√°rio 1 (Baseline): Prompt = Pergunta

* Cen√°rio 2 (RAG Est√°tico): Prompt = Pergunta + Trechos do PDF

* Cen√°rio 3 (Dual Context): Prompt = Pergunta + Trechos do PDF + Telemetria Atual (JSON)

## Como Executar

### Pr√©-requisitos

* Docker e Docker Compose instalados.

* (Opcional) Chave de API da Groq ou Google AI Studio.

### Configura√ß√£o

1. Renomeie ou crie o arquivo .env na raiz:

````
# Broker MQTT (p√∫blico ou privado)
MQTT_BROKER_ADDRESS=<ip ou endereco>
MQTT_BROKER_PORT=<porta>
MQTT_USERNAME=<login>
MQTT_PASSWORD=<senha>
MQTT_TOPIC_SENSORS=industrial/lathe/sensors
MQTT_TOPIC_COMMANDS=industrial/lathe/commands
LOG_MQTT_EVENTS=false

# Chaves de API (Necess√°rio para a infer√™ncia real)
GROQ_API_KEY=sua_chave_aqui
GOOGLE_API_KEY=sua_chave_aqui
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_CHAT_TIMEOUT=600
HUGGING_FACE_TOKEN=

# Vetoriza√ß√£o / RAG
VECTOR_BACKEND_DEFAULT=chroma  # op√ß√µes: chroma, faiss, weaviate, pinecone
CHUNK_SIZE_DEFAULT=1000
CHUNK_OVERLAP_DEFAULT=200
EMBEDDING_MODEL_DEFAULT=all-MiniLM-L6-v2
FAISS_INDEX_DIR=/app/data/faiss_index
CHROMA_DB_PATH=/app/data/chromadb

# Relat√≥rios de experimentos
SUMMARY_OUTPUT_DIR=/app/data/summaries
SUMMARY_MAX_RECENT=50

# Weaviate (opcional)
WEAVIATE_URL=http://weaviate:8080  # container local j√° incluso no docker-compose
WEAVIATE_API_KEY=                  # deixe vazio para uso local sem autentica√ß√£o
WEAVIATE_CLASS=IndustrialManual

# Pinecone (opcional)
PINECONE_API_KEY=sua_chave_pinecone
PINECONE_ENVIRONMENT=us-east-1
PINECONE_INDEX=industrial-dual-rag
PINECONE_NAMESPACE=default
PINECONE_DIMENSION=384
PINECONE_CLOUD=aws
PINECONE_REGION=us-east-1
````

2. Suba os cont√™ineres:

````
docker-compose up --build
````

3. Acesse a interface web:

* URL: `http://localhost:8501`

### Reprocessar base ao trocar o backend vetorial

- Os PDFs enviados ficam salvos em `/app/data/uploads` e s√£o reutilizados para qualquer backend habilitado (Chroma, FAISS, Weaviate ou Pinecone).
- Ao mudar o backend no painel lateral, clique no bot√£o `‚ôªÔ∏è Reprocessar base existente` para reindexar automaticamente todos os manuais j√° carregados com os novos par√¢metros de chunking/embedding.
- Esse passo evita subir os PDFs novamente e garante que o backend rec√©m-selecionado receba os mesmos documentos antes de executar consultas.
- Para Pinecone ou Weaviate externos, certifique-se de preencher as vari√°veis no `.env` antes de reprocessar para evitar erros de autentica√ß√£o.

### Modelo de embedding √ó backend vetorial

- O modelo de embedding padr√£o √© `all-MiniLM-L6-v2` (Sentence-Transformers). Ele √© configur√°vel tanto pelo `.env` (`EMBEDDING_MODEL_DEFAULT`) quanto pelo campo **"Modelo de embedding"** no Streamlit.
- Alterar o backend de indexa√ß√£o **n√£o** troca automaticamente o modelo de embedding; a escolha do SentenceTransformer √© global. Se voc√™ mudar o modelo, reexecute `‚ôªÔ∏è Reprocessar base existente` para gerar vetores com o novo encoder para Chroma/FAISS/Weaviate/Pinecone.
- Chroma usa o `embedding_function` definido no backend, mas FAISS/Weaviate/Pinecone carregam explicitamente o modelo informado, garantindo compara√ß√µes justas entre backends mesmo quando voc√™ alterna entre eles.
- Documentamos essa decis√£o para atender ao crit√©rio experimental do professor: o estudo mant√©m o mesmo encoder enquanto troca apenas o armazenamento vetorial, isolando o efeito do backend.

#### Outros encoders poss√≠veis (SentenceTransformers):

- all-mpnet-base-v2 ‚Äì melhor recall geral, por√©m vetores de 768 dimens√µes (mais pesados).
- multi-qa-mpnet-base-dot-v1 ‚Äì otimizado para perguntas/respostas, boa escolha para manuais.
- gte-large (GEMMA Text Embedding) ‚Äì alternativa recente, 1024 dimens√µes.
paraphrase-multilingual-mpnet-base-v2 ‚Äì se precisar suportar PT/EN simultaneamente.

Basta digitar o nome exato no campo ‚ÄúModelo de embedding‚Äù da UI (desde que o pacote sentence-transformers o suporte) e reindexar.

### Persist√™ncia de dados e relat√≥rios

- O servi√ßo `api` monta `./data/api` (host) em `/app/data`, concentrando `experiment_logs.csv`, PDFs processados e os resumos gerados em `SUMMARY_OUTPUT_DIR`. Assim, voc√™ pode abrir os CSV/HTML fora do Docker sem depender da UI.
- O cont√™iner do Weaviate escreve em `./data/weaviate`; mantenha essa pasta para preservar o √≠ndice local entre rebuilds.
- Antes de executar `docker-compose up`, crie as pastas necess√°rias: `mkdir -p data/api data/weaviate`.

## Protocolo de Experimento

Para reproduzir os resultados do relat√≥rio cient√≠fico:

### Passo 1: Prepara√ß√£o

1. Na barra lateral, selecione o LLM (Recomendado: Groq/Llama3 para velocidade).
Recommended Trio

    - Groq ‚Üí llama-3.3-70b-versatile ¬∑ 131072 tok
    - Gemini ‚Üí Gemini 2.5 Flash ¬∑ 1048576 tok
    - Local ‚Üí Ollama llama3.2:3b (ja carregado pelo docker-compose)

2. Fa√ßa upload do arquivo manual_torno.pdf (dispon√≠vel na pasta /docs ou use um gen√©rico).

3. Clique em "Indexar Manual".

4. Opcional: ajuste o seletor "Vari√°veis de telemetria enviadas ao LLM" para limitar quais sinais (temperatura, vibra√ß√£o, corrente, status) entram no prompt dos cen√°rios com contexto din√¢mico.

### Passo 2: Execu√ß√£o do Teste

1. Estado Normal:

* Deixe o simulador em "Opera√ß√£o Normal".

* Selecione Cen√°rio 3.

* Pergunte: "Qual o estado da m√°quina?".

* Resultado Esperado: O LLM deve informar que os par√¢metros est√£o nominais.

2. Inje√ß√£o de Falha:

* Clique no bot√£o "üî• Falha T√©rmica".

* Aguarde a temperatura no painel subir acima de 90¬∞C.

3. Compara√ß√£o de Cen√°rios (Ablation Study):

* Cen√°rio 1 (Baseline): Pergunte "O que devo fazer?". O LLM n√£o saber√° da temperatura alta.

* Cen√°rio 3 (Dual Context): Pergunte "O que devo fazer?". O LLM deve detectar o superaquecimento (via Telemetria) e citar o procedimento de resfriamento (via Manual PDF).

4. Registro e Consolida√ß√£o:

* Ative o checkbox "Gravar logs de experimentos", informe um gabarito (quando houver) e execute diagn√≥sticos.
* As m√©tricas s√£o gravadas em `/app/data/experiment_logs.csv`. Ap√≥s capturar os cen√°rios desejados, clique no bot√£o "üìä Gerar resumo autom√°tico" da barra lateral para consolidar CSVs e gr√°ficos em `SUMMARY_OUTPUT_DIR` (padr√£o: `/app/data/summaries`). Se preferir inspe√ß√£o manual, continue usando o notebook `notebooks/experiment_summary.ipynb`, que consome os mesmos arquivos.

### Gabaritos de refer√™ncia

- O campo "Gabarito (refer√™ncia para m√©tricas)" compara a resposta do LLM com um texto oficial para calcular accuracy/BLEU/ROUGE.
- Utilize o arquivo `docs/gabarito.md`, que traz respostas derivadas do **Manual de Opera√ß√£o e Manuten√ß√£o ‚Äì ROMI T 240** para os cen√°rios Normal, Falha T√©rmica e Desbalanceamento. Basta copiar o trecho do cen√°rio correspondente para o campo da UI antes de rodar o teste.
- Se adicionar novas falhas ou traduzir o manual, edite o arquivo mantendo a estrutura "Estado geral ‚Üí Evid√™ncias ‚Üí A√ß√µes" para preservar a consist√™ncia estat√≠stica.

## Limita√ß√µes Operacionais

- **Broker MQTT p√∫blico:** o padr√£o (`test.mosquitto.org`) n√£o oferece SLA, podendo sofrer quedas ou limita√ß√£o de mensagens. Para medi√ß√µes consistentes, substitua por um broker privado (Eclipse Mosquitto local ou servi√ßo gerenciado) e atualize as vari√°veis `MQTT_*` no `.env`.
- **Depend√™ncia de APIs externas:** provedores como Groq e Google imp√µem limites de taxa e de tokens; lat√™ncias ou erros 429 impactam diretamente o tempo de diagn√≥stico. Para cen√°rios offline, mantenha Ollama com o modelo baixado previamente e ajuste `OLLAMA_CHAT_TIMEOUT` conforme o tamanho do prompt.
- **Estado dos backends vetoriais:** cada backend mant√©m seu pr√≥prio √≠ndice; ao alternar entre Chroma/FAISS/Weaviate/Pinecone √© obrigat√≥rio reprocessar os PDFs (bot√£o `‚ôªÔ∏è Reprocessar base existente`). Servi√ßos externos ainda exigem conectividade est√°vel e chaves v√°lidas.
- **Persist√™ncia e espa√ßo em disco:** logs, uploads e resumos ficam em `./data/api`. O volume cresce com novos experimentos; fa√ßa limpeza peri√≥dica ou mova os arquivos gerados para armazenamento frio. O √≠ndice do Weaviate consome `./data/weaviate` e pode ultrapassar centenas de MB dependendo da base.

## Estrutura de Arquivos

````
.
‚îú‚îÄ‚îÄ api/                # Backend FastAPI e l√≥gica RAG (uploads, endpoints, vetores)
‚îú‚îÄ‚îÄ web/                # Frontend Streamlit com painel experimental
‚îú‚îÄ‚îÄ simulator/          # Publicador MQTT de telemetria e inje√ß√£o de falhas
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ api/            # Uploads, √≠ndices FAISS, logs e resumos persistidos
‚îÇ   ‚îî‚îÄ‚îÄ weaviate/       # Volume local do cont√™iner Weaviate
‚îú‚îÄ‚îÄ docs/               # Papel, apresenta√ß√£o, gabarito oficial e instru√ß√µes extras
‚îú‚îÄ‚îÄ notebooks/          # Consolida√ß√£o opcional dos experimentos (Plotly/Pandas)
‚îú‚îÄ‚îÄ docker-compose.yml  # Orquestra√ß√£o
‚îî‚îÄ‚îÄ README.md
````

## Tecnologias Utilizadas

* **LLMs**: Groq Llama 3.x (8B/70B), Gemini 1.5/2.5 Flash, Ollama Llama3.2 3B para o modo offline.
* **RAG / Embeddings**: Sentence-Transformers (padr√£o `all-MiniLM-L6-v2`, com suporte a all-mpnet-base-v2, multi-qa-mpnet, gte-large, etc.), vetoriza√ß√£o servida por ChromaDB, FAISS, Weaviate e Pinecone.
* **Backend/API**: FastAPI + Python, langchain-community para integra√ß√£o com vetores, pandas/plotly para sumariza√ß√£o experimental.
* **Frontend**: Streamlit (dashboard, upload, logging e controle de falhas) + Requests para chamadas √† API.
* **IoT / Mensageria**: MQTT (paho-mqtt), broker Mosquitto p√∫blico/local, comandos de falha em tempo real.


**Autores**: Amauri Cunha, Yessica Maria Valencia Lemos
**Data**: 06 de Dezembro 2025